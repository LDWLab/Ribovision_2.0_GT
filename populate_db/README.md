# Populating DESIRE

## Introduction

DESIRE is a MySQL database that provides a relational abstraction for species taxonomy, polymers, domains, residues, annotation data, alignments, and secondary structures.

The schema for DESIRE is quite complex and includes many tables:

![DESIRE schema](./DESIRE_schema.svg)

The table can be generated with [create_tables.sql](./create_tables.sql), which is autogenerated from MySQL workbench. If the file is too old it should be generated anew by logging in MySQL Workbench and using the reverse engineer MySQL syntax menu.

Every month a backup of the MySQL database is created at /home/Desire-Server/SEREB_latest.sql This file can restore the entire DESIRE database by recreating the DESIRE schema.

To correctly update each of these tables and their relationships there are python scripts which establish a connection to the server and take different data as inputs. The scripts are organized in folders that indicate what type of data will be handled.

When adding new data to the database you are changing the data served to users online, therefore it is imperative to have multiple checks on the accuracy of the data. This is also the reason many of the upload steps are broken down in smaller steps and involve intermediary files. My reccomendation is to use the test schema SEREB_test on Apollo2 to ensure you are adding things correctly and without errors, before amending the DESIRE schema which is being shown to users online.

This guide will go over the steps for uploading new species, their taxonomy, and updating the existing alignments with sequences for these species. Additionally, the guide has a section on uploading a new alignment to the server.

The file [launch.json](../.vscode/launch.json) has debugging configurations for several upload scripts, which show the necessary command line arguments.

## Taxonomy

The first step in adding new species involves updating the taxonomy. DESIRE treats taxonomy as a recursive relationship between the following taxonomic levels:

superkingdom, phylum, class, order, family, genus, species, strain

each taxonomic level has a parent, except the superkingdoms, which have a parent set to 0.

New species can be uploaded by providing a list of taxonomic identifiers to the [upload_taxonomy2.py](./Phylogeny/upload_taxonomy2.py) script:

> upload_taxonomy2.py PATH_TO_NEW_TAXIDS NEW_TAXONOMY_JSON DB_USERNAME -dl -commit

The first argument of the script (PATH_TO_NEW_TAXIDS) is a text file that has the taxids for new species separated with newlines.

The second argument of the script (NEW_TAXONOMY_JSON) is a path to the location where the taxonomy recursive datastructure should be located. If you do not have that json file the script can automatically download and generate this file with the -dl flag.

The flag -commit commits the upload statements to the database. You might want to do a dry run test without this flag before pushing changes to the database.

## Polymers

Uploading new polymer entries to the database comes next. This involves generating a csv file that contains the species taxids, polymer accessions, accession source, polymer names, and polymer sequences from a fasta sequence file. This csv is then used to upload the data to the DESIRE database.

1. Parsing accessions - to generate the csv from a fasta file there are 2 files that can be used: [parse_accession.py](./Polymers/parse_accession.py) and [parse_accession2.py](./Polymers/parse_accession2.py). Both of them try to do some cleanup of the fasta and generate as clean of a csv as possible. The difference is [parse_accession.py](./Polymers/parse_accession.py) was written to facilitate the initial upload of DESIRE data and uses %%% as identifier for lines that should contain the taxids.

	Therefore for new data with properly formatted fasta you should be using [parse_accession2.py](./Polymers/parse_accession2.py). The format of the identifier line in the fasta should look like this:

	> eL06_13706_SYNRA|ORZ00342.1

	The identifier is spearated in two by the pipe symbol (\|). The first element defines the polymer name, species taxid, and up to 5 letter species abbreviation, separated by underscore (\_). The species abbreviation is optional, but the separator isn't (eL06_13706\_\|ORZ00342.1). The second element is the accession ID. The script tries to guess whether the accession comes from UNIPROT or NCBI but can make mistakes with pdb ids, so any csv output should be **manually checked**. To parse many fasta files in a directory you can execute script like so:

	> for f in PATH_TO_FASTAS/*.fas; do ./parse_accession2.py -a $f -o ./CSV/OUTPUT_CSV.csv ;done

	The output CSV file is opened in append mode so new polymer entries will be added to the bottom.

2. Uploading accessions - with the generated and checked CSV file you can upload new polymer entries to DESIRE with the [upload_accession.py](./Polymers/upload_accession.py) script:

	>./upload_accession.py -c ./CSV/OUTPUT_CSV.csv

	The script skips lines starting with #.
	This script is a little old so the argument parameters do not allow for flexible adjustment of schema, host, and commit. If you want to use the SEREB_test schema you will have to directly edit the script and change the database= parameter on line 29.

## Alignments

The format of the sequence identifier line of a alignment or sequence file has 3 fields separated by \_:

> uL02b_190304_FUSNN

The first **FOUR letters** in the first field indicate the protein name. In the given example the protein name is uL02. The second field provides the taxID of the species. The third field is optional (but the separator is required) and it gives a species abbreviation, which is not uploaded.

The format of the sequence identifier line of a permuted alignment has 4 fields separated by \_:

> uL02b_190304_FUSNN/1-276_161-185,134-143

Notice the third field here is FUSNN/1-276, the numbers after the slash are a leftover of jalview and this is one of the reasons the scripts mostly ignore the third field.

The fourth field in this example is 161-185,134-143. The comma here separates different ranges that correspond to residue numbering present in the polymer entry for the given sequence. In this alignment, the sequence of uL02 FUSNN is permuted and has two ranges of residues, ordered like so:
1. from the 161st residue to the 185th residue, 
2. from the 134th residue to the 143rd residue.

There can be more any number of ranges.

### Appending to existing alignment

Prerequisite - MAFFT

If the alignment already exists within DESIRE the script to use is [appendSeqToAln.py](./Alignments/appendSeqToAln.py). If you know the alignment id it can be specified with an input argument -aln_id, otherwise the script will try to find it by using the provided fasta file name. 

> ./appendSeqToAln.py PATH_TO_FASTA.fas SOURCE_STRING -commit

The PATH_TO_FASTA.fas variable is a path to a fasta file with **UNALIGNED** sequences. This script will fetch the corresponding alignment you are trying to append to and use mafft-add to align the provided sequences, then it will reupload the modified alignment.

The SOURCE_STRING argument is required and it determines the superkingdom of the **alignment**. Note this is not of the sequences being uploaded. For example, when adding eukaryotic sequences to an Archaea-Eukarya alignment the SOURCE_STRING should be **ae**.
For now it does not support cellular compartment SOURCE_STRING (e.g. **m** or **c**) but some modifications in the SQL and script should allow it to do that too.

### Adding a new alignment

If you are adding a new alignment entry to DESIRE the script to use is [upload_aln.py](./Alignments/upload_aln.py).

> ./upload_aln.py PATH_TO_FASTA_ALN.fas SOURCE_STRING -commit

The PATH_TO_FASTA_ALN.fas variable is a path to a fasta file with **ALIGNED** sequences. This script directly adds the alignment data to DESIRE as provided.

This script can also use the input argument -aln_id. If provided it will append the provided **alignment** data. However, it does not perform checks on appending sequences to an existing alignment, therefore you need to know that the added sequences **WILL NOT** introduce gaps in the already present sequences. For that reason it is not reccomended to use it for adding new aligned sequences to already present alignment, to do that use[appendSeqToAln.py](./Alignments/appendSeqToAln.py) instead.

The SOURCE_STRING argument is required and is the same as previously described, however since this script is used to **ADD** new alignments you should be able to push **m** or **c** to DESIRE.